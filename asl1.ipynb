{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3092313",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2516f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c462d",
   "metadata": {},
   "source": [
    "## Load Dataset and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bea80e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84000 files belonging to 28 classes.\n",
      "Using 67200 files for training.\n",
      "Found 84000 files belonging to 28 classes.\n",
      "Using 16800 files for validation.\n",
      "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "# Path to dataset\n",
    "data_dir = \"asl_alphabet/train\"\n",
    "\n",
    "# Image size\n",
    "img_height, img_width = 200, 200\n",
    "batch_size = 32\n",
    "\n",
    "# Load dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Improve performance with caching\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab7e83",
   "metadata": {},
   "source": [
    "## Build and Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf667547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avetisavagyan/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  18/2100\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:47\u001b[0m 340ms/step - accuracy: 0.0366 - loss: 3.5786"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      2\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(img_height, img_width, \u001b[38;5;241m3\u001b[39m)),\n\u001b[1;32m      3\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;28mlen\u001b[39m(class_names), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m ])\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/Waterloo/Side Projects/asl-recognizer/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    \n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53f3d3",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9286 - loss: 3.0502\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(val_ds)\n",
    "model.save('asl_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6c102",
   "metadata": {},
   "source": [
    "## Real-Time Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ca5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747506146.182545 2933896 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1747506146.189530 3040858 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747506146.194368 3040858 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📷 Press 'q' to quit.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction vector: [4.3271273e-05 2.6539783e-11 5.7072118e-11 1.6165095e-11 1.0910273e-03\n",
      " 8.5204687e-05 1.2942136e-03 1.0957890e-05 5.4210452e-03 2.8607893e-01\n",
      " 1.3490508e-07 9.9398656e-11 3.5337283e-04 1.9069981e-03 1.6991702e-05\n",
      " 8.1713956e-08 1.4513165e-12 7.3006372e-11 4.0591435e-06 3.4377903e-09\n",
      " 2.4491246e-13 2.8908500e-08 1.1833234e-04 1.4831914e-03 7.0186466e-01\n",
      " 9.7106101e-07 1.1474699e-06 5.2817421e-11 2.2536650e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Prediction vector: [4.3140564e-05 2.6937006e-11 5.6678644e-11 1.5920853e-11 1.0891942e-03\n",
      " 8.2931256e-05 1.3105884e-03 1.1124772e-05 5.4706060e-03 2.9090893e-01\n",
      " 1.3820991e-07 9.9651676e-11 3.6357355e-04 1.9473761e-03 1.6809474e-05\n",
      " 8.1575969e-08 1.4460634e-12 7.5277430e-11 4.0050168e-06 3.4022258e-09\n",
      " 2.5003174e-13 2.9164527e-08 1.1943171e-04 1.4966906e-03 6.9690484e-01\n",
      " 9.6823305e-07 1.1596723e-06 5.3464878e-11 2.2830129e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Prediction vector: [4.3297110e-05 2.6970709e-11 5.6750642e-11 1.5890804e-11 1.0904098e-03\n",
      " 8.2870305e-05 1.3056435e-03 1.1122629e-05 5.4473532e-03 2.9076517e-01\n",
      " 1.3728366e-07 9.9467587e-11 3.6353839e-04 1.9473503e-03 1.6817205e-05\n",
      " 8.1580339e-08 1.4512569e-12 7.5082357e-11 4.0191976e-06 3.4078798e-09\n",
      " 2.5029062e-13 2.9033739e-08 1.1899368e-04 1.5002390e-03 6.9707310e-01\n",
      " 9.6891665e-07 1.1594059e-06 5.3515234e-11 2.2772269e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Prediction vector: [4.3551670e-05 2.7460881e-11 5.7168912e-11 1.5817715e-11 1.0953051e-03\n",
      " 8.1958591e-05 1.3056714e-03 1.1205621e-05 5.4642139e-03 2.9289797e-01\n",
      " 1.3792406e-07 1.0019802e-10 3.7215537e-04 1.9786297e-03 1.6838885e-05\n",
      " 8.2196891e-08 1.4783033e-12 7.6651768e-11 4.0609007e-06 3.4463343e-09\n",
      " 2.5550138e-13 2.9026152e-08 1.1945177e-04 1.5067694e-03 6.9487214e-01\n",
      " 9.7050076e-07 1.1698461e-06 5.4410049e-11 2.2771639e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Prediction vector: [4.4476783e-05 2.9064478e-11 5.9316649e-11 1.6118608e-11 1.0958926e-03\n",
      " 8.0802318e-05 1.3211407e-03 1.1487780e-05 5.4612923e-03 2.9853070e-01\n",
      " 1.4115663e-07 1.0404321e-10 3.8777379e-04 2.0391543e-03 1.6926251e-05\n",
      " 8.4945192e-08 1.5684456e-12 8.1817393e-11 4.1624039e-06 3.5711656e-09\n",
      " 2.7140955e-13 2.9541374e-08 1.2035951e-04 1.5120297e-03 6.8914068e-01\n",
      " 9.7391762e-07 1.2008250e-06 5.7403568e-11 2.3074613e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Prediction vector: [4.52392123e-05 3.07043765e-11 6.11538528e-11 1.63026172e-11\n",
      " 1.09939161e-03 7.93335639e-05 1.32235547e-03 1.17374775e-05\n",
      " 5.46786748e-03 3.02590460e-01 1.43703232e-07 1.07410074e-10\n",
      " 4.05026978e-04 2.11096369e-03 1.70910789e-05 8.70772539e-08\n",
      " 1.67256703e-12 8.73024569e-11 4.28569410e-06 3.70310738e-09\n",
      " 2.89105437e-13 2.98940073e-08 1.20831115e-04 1.52607821e-03\n",
      " 6.84964716e-01 9.81957442e-07 1.23314783e-06 6.05488160e-11\n",
      " 2.32192731e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction vector: [4.5197001e-05 3.1241870e-11 6.1296503e-11 1.6222296e-11 1.0955537e-03\n",
      " 7.8230049e-05 1.3337892e-03 1.1853206e-05 5.4828408e-03 3.0553460e-01\n",
      " 1.4586826e-07 1.0841688e-10 4.1264165e-04 2.1351059e-03 1.7043372e-05\n",
      " 8.7532101e-08 1.6870860e-12 8.9687750e-11 4.2910801e-06 3.7203145e-09\n",
      " 2.9701916e-13 3.0147238e-08 1.2186549e-04 1.5283978e-03 6.8196189e-01\n",
      " 9.7970883e-07 1.2398884e-06 6.1616857e-11 2.3418083e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.5245084e-05 3.1275465e-11 6.1428813e-11 1.6282977e-11 1.0886100e-03\n",
      " 7.8310208e-05 1.3354068e-03 1.1947460e-05 5.4814396e-03 3.0613804e-01\n",
      " 1.4632107e-07 1.0851194e-10 4.1406037e-04 2.1369841e-03 1.7135633e-05\n",
      " 8.8109658e-08 1.7002677e-12 9.0168102e-11 4.2833894e-06 3.7199985e-09\n",
      " 2.9763418e-13 3.0132835e-08 1.2279527e-04 1.5142895e-03 6.8137354e-01\n",
      " 9.7768907e-07 1.2467394e-06 6.2270862e-11 2.3542753e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction vector: [4.52149143e-05 3.12970275e-11 6.12617596e-11 1.63260568e-11\n",
      " 1.09002611e-03 7.83060677e-05 1.34218973e-03 1.20871455e-05\n",
      " 5.52097382e-03 3.07117969e-01 1.47203053e-07 1.08074306e-10\n",
      " 4.16159717e-04 2.15034699e-03 1.72521777e-05 8.82009203e-08\n",
      " 1.69840812e-12 9.03506367e-11 4.25066628e-06 3.68911546e-09\n",
      " 2.95962094e-13 3.00712450e-08 1.23117818e-04 1.51267741e-03\n",
      " 6.80331111e-01 9.78644835e-07 1.25258930e-06 6.23099905e-11\n",
      " 2.35795029e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Prediction vector: [4.54202418e-05 3.17995560e-11 6.22431690e-11 1.64706668e-11\n",
      " 1.09469518e-03 7.82747884e-05 1.34541851e-03 1.20037594e-05\n",
      " 5.50753716e-03 3.07586938e-01 1.48430175e-07 1.10012145e-10\n",
      " 4.16965951e-04 2.14999658e-03 1.71661159e-05 8.87457290e-08\n",
      " 1.71907258e-12 9.16229453e-11 4.29631564e-06 3.74860853e-09\n",
      " 3.02190239e-13 3.04519894e-08 1.23111939e-04 1.52314943e-03\n",
      " 6.79855704e-01 9.82429128e-07 1.25417796e-06 6.30275832e-11\n",
      " 2.36823034e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction vector: [4.53917310e-05 3.15998928e-11 6.19865201e-11 1.64578785e-11\n",
      " 1.08721061e-03 7.83303039e-05 1.34782598e-03 1.20756758e-05\n",
      " 5.50492201e-03 3.07933420e-01 1.48244496e-07 1.09650525e-10\n",
      " 4.16893628e-04 2.15116749e-03 1.72256041e-05 8.89488661e-08\n",
      " 1.71896026e-12 9.14275669e-11 4.27061059e-06 3.73315201e-09\n",
      " 3.00731364e-13 3.03469676e-08 1.23290825e-04 1.51251745e-03\n",
      " 6.79526091e-01 9.80494974e-07 1.25718066e-06 6.29112942e-11\n",
      " 2.36905704e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.56545640e-05 3.20538110e-11 6.25922716e-11 1.65418616e-11\n",
      " 1.08580361e-03 7.81583221e-05 1.35128503e-03 1.21544745e-05\n",
      " 5.50415413e-03 3.09614003e-01 1.49268075e-07 1.10794512e-10\n",
      " 4.20093100e-04 2.16471124e-03 1.72490963e-05 8.96597641e-08\n",
      " 1.74359594e-12 9.28894114e-11 4.29442616e-06 3.76570908e-09\n",
      " 3.05367900e-13 3.04994963e-08 1.23607300e-04 1.51358685e-03\n",
      " 6.77824616e-01 9.82094434e-07 1.26378393e-06 6.39099954e-11\n",
      " 2.38116438e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.5565597e-05 3.1963137e-11 6.2611111e-11 1.6521895e-11 1.0880566e-03\n",
      " 7.8014717e-05 1.3509791e-03 1.2093456e-05 5.4984014e-03 3.0944383e-01\n",
      " 1.4914393e-07 1.1086888e-10 4.1882563e-04 2.1571810e-03 1.7188398e-05\n",
      " 8.9518416e-08 1.7374569e-12 9.2598727e-11 4.2874794e-06 3.7651691e-09\n",
      " 3.0519486e-13 3.0551128e-08 1.2310820e-04 1.5191523e-03 6.7800277e-01\n",
      " 9.8423561e-07 1.2625161e-06 6.3482566e-11 2.3802483e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.5689929e-05 3.2063501e-11 6.2373044e-11 1.6411645e-11 1.0942147e-03\n",
      " 7.7807956e-05 1.3473724e-03 1.2117519e-05 5.5119991e-03 3.0887789e-01\n",
      " 1.4819899e-07 1.1006037e-10 4.2234623e-04 2.1731786e-03 1.7235958e-05\n",
      " 8.9444463e-08 1.7346478e-12 9.2317390e-11 4.3005325e-06 3.7652459e-09\n",
      " 3.0526219e-13 3.0293130e-08 1.2333787e-04 1.5202797e-03 6.7853278e-01\n",
      " 9.8329110e-07 1.2616800e-06 6.3596690e-11 2.3689138e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Prediction vector: [4.5907775e-05 3.2360916e-11 6.3067100e-11 1.6523232e-11 1.0908010e-03\n",
      " 7.7792647e-05 1.3523892e-03 1.2183274e-05 5.4983492e-03 3.1040400e-01\n",
      " 1.4877585e-07 1.1102621e-10 4.2344589e-04 2.1822054e-03 1.7293445e-05\n",
      " 9.0319773e-08 1.7573858e-12 9.3432470e-11 4.3168229e-06 3.7895318e-09\n",
      " 3.0887806e-13 3.0489449e-08 1.2353466e-04 1.5195580e-03 6.7700708e-01\n",
      " 9.8524890e-07 1.2697718e-06 6.4351233e-11 2.3858059e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.60055162e-05 3.27086448e-11 6.34210878e-11 1.66158181e-11\n",
      " 1.08890270e-03 7.74036162e-05 1.35762175e-03 1.22436559e-05\n",
      " 5.50400559e-03 3.11577469e-01 1.50354992e-07 1.12076744e-10\n",
      " 4.26812621e-04 2.19401577e-03 1.72894743e-05 9.06946411e-08\n",
      " 1.77593053e-12 9.49493609e-11 4.31794342e-06 3.80880349e-09\n",
      " 3.13025268e-13 3.07162509e-08 1.23912716e-04 1.52203243e-03\n",
      " 6.75805390e-01 9.88291390e-07 1.27791259e-06 6.51105975e-11\n",
      " 2.40026595e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Prediction vector: [4.6009307e-05 3.2715927e-11 6.3236007e-11 1.6495595e-11 1.0884370e-03\n",
      " 7.7181852e-05 1.3553901e-03 1.2247012e-05 5.4995450e-03 3.1168249e-01\n",
      " 1.4973359e-07 1.1182600e-10 4.2840262e-04 2.2009397e-03 1.7283332e-05\n",
      " 9.0606243e-08 1.7736953e-12 9.4894280e-11 4.3262798e-06 3.8113233e-09\n",
      " 3.1344626e-13 3.0588023e-08 1.2386692e-04 1.5237374e-03 6.7569804e-01\n",
      " 9.8602948e-07 1.2754549e-06 6.5076548e-11 2.3944941e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Prediction vector: [4.59924850e-05 3.26168155e-11 6.30464778e-11 1.65080675e-11\n",
      " 1.08647707e-03 7.73796346e-05 1.35156675e-03 1.22143492e-05\n",
      " 5.49078360e-03 3.10875654e-01 1.49117213e-07 1.11568706e-10\n",
      " 4.26951039e-04 2.19446770e-03 1.72742457e-05 9.03849298e-08\n",
      " 1.77026254e-12 9.44391301e-11 4.33227706e-06 3.81355747e-09\n",
      " 3.12162487e-13 3.05167092e-08 1.23610676e-04 1.52052799e-03\n",
      " 6.76531494e-01 9.84029157e-07 1.27273381e-06 6.47086065e-11\n",
      " 2.38736189e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Prediction vector: [4.58733521e-05 3.25695824e-11 6.27428873e-11 1.64123506e-11\n",
      " 1.09014392e-03 7.70612314e-05 1.34987861e-03 1.22061911e-05\n",
      " 5.49749518e-03 3.10953468e-01 1.48575026e-07 1.10988684e-10\n",
      " 4.28210042e-04 2.19661370e-03 1.72229957e-05 9.01922590e-08\n",
      " 1.76435407e-12 9.43639056e-11 4.34769208e-06 3.80710574e-09\n",
      " 3.12103696e-13 3.04635108e-08 1.23251244e-04 1.52499857e-03\n",
      " 6.76438868e-01 9.81123776e-07 1.26986583e-06 6.45380416e-11\n",
      " 2.37853412e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.5932724e-05 3.2795652e-11 6.3066302e-11 1.6472048e-11 1.0916011e-03\n",
      " 7.6831268e-05 1.3529856e-03 1.2262407e-05 5.5117933e-03 3.1183344e-01\n",
      " 1.4946200e-07 1.1171794e-10 4.3083742e-04 2.2089474e-03 1.7264390e-05\n",
      " 9.0519116e-08 1.7762688e-12 9.5335323e-11 4.3514387e-06 3.8117021e-09\n",
      " 3.1510317e-13 3.0627728e-08 1.2355384e-04 1.5318687e-03 6.7551649e-01\n",
      " 9.8399596e-07 1.2784228e-06 6.4923816e-11 2.3932160e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.5982710e-05 3.2635148e-11 6.3003630e-11 1.6436326e-11 1.0902210e-03\n",
      " 7.6977623e-05 1.3445726e-03 1.2166556e-05 5.4836124e-03 3.1049007e-01\n",
      " 1.4847710e-07 1.1163864e-10 4.2806927e-04 2.1984950e-03 1.7212433e-05\n",
      " 9.0025004e-08 1.7723694e-12 9.4572447e-11 4.3508971e-06 3.8181471e-09\n",
      " 3.1312409e-13 3.0496498e-08 1.2274880e-04 1.5331116e-03 6.7691171e-01\n",
      " 9.8657677e-07 1.2744819e-06 6.4440911e-11 2.3806063e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Prediction vector: [4.6118341e-05 3.2843787e-11 6.3541290e-11 1.6533677e-11 1.0921867e-03\n",
      " 7.7246288e-05 1.3468285e-03 1.2196068e-05 5.4865852e-03 3.1083727e-01\n",
      " 1.4881596e-07 1.1231423e-10 4.2887416e-04 2.2043260e-03 1.7291493e-05\n",
      " 9.0574034e-08 1.7874772e-12 9.5116082e-11 4.3708278e-06 3.8356665e-09\n",
      " 3.1511512e-13 3.0616448e-08 1.2298202e-04 1.5358165e-03 6.7654663e-01\n",
      " 9.8921589e-07 1.2795107e-06 6.4820732e-11 2.3872239e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.59306975e-05 3.26893859e-11 6.30958272e-11 1.64508043e-11\n",
      " 1.09154405e-03 7.70907063e-05 1.34663645e-03 1.21885196e-05\n",
      " 5.49142668e-03 3.10406059e-01 1.48269564e-07 1.11592374e-10\n",
      " 4.27629711e-04 2.20310269e-03 1.72487198e-05 9.01452211e-08\n",
      " 1.76875463e-12 9.45583056e-11 4.36115124e-06 3.81568377e-09\n",
      " 3.13395143e-13 3.05537071e-08 1.22690428e-04 1.53739459e-03\n",
      " 6.76975787e-01 9.86886562e-07 1.27444196e-06 6.42282130e-11\n",
      " 2.38344088e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.5978570e-05 3.2758928e-11 6.3275177e-11 1.6435566e-11 1.0902336e-03\n",
      " 7.6888224e-05 1.3472604e-03 1.2201247e-05 5.4783016e-03 3.1096068e-01\n",
      " 1.4846769e-07 1.1176281e-10 4.2832570e-04 2.2032850e-03 1.7191918e-05\n",
      " 9.0256556e-08 1.7775483e-12 9.5234730e-11 4.3697992e-06 3.8199155e-09\n",
      " 3.1501394e-13 3.0607726e-08 1.2266847e-04 1.5363281e-03 6.7643517e-01\n",
      " 9.8738201e-07 1.2778464e-06 6.4646351e-11 2.3855359e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6063116e-05 3.3052918e-11 6.3528786e-11 1.6544838e-11 1.0941346e-03\n",
      " 7.6898374e-05 1.3518584e-03 1.2234156e-05 5.4980456e-03 3.1129828e-01\n",
      " 1.4964562e-07 1.1243957e-10 4.2993299e-04 2.2119987e-03 1.7231829e-05\n",
      " 9.0504308e-08 1.7846320e-12 9.5888741e-11 4.3803984e-06 3.8402108e-09\n",
      " 3.1821103e-13 3.0803523e-08 1.2301833e-04 1.5392140e-03 6.7605489e-01\n",
      " 9.8774206e-07 1.2806468e-06 6.4986350e-11 2.3934043e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction vector: [4.5800003e-05 3.2519799e-11 6.2695509e-11 1.6349144e-11 1.0905851e-03\n",
      " 7.7004144e-05 1.3432823e-03 1.2153675e-05 5.4809027e-03 3.0997786e-01\n",
      " 1.4730117e-07 1.1068700e-10 4.2669193e-04 2.1935469e-03 1.7172692e-05\n",
      " 8.9860677e-08 1.7596624e-12 9.4101851e-11 4.3699647e-06 3.8094368e-09\n",
      " 3.1174076e-13 3.0377809e-08 1.2258915e-04 1.5315447e-03 6.7743689e-01\n",
      " 9.8235023e-07 1.2674871e-06 6.4202609e-11 2.3702371e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.59966359e-05 3.29796017e-11 6.30673291e-11 1.62983672e-11\n",
      " 1.09289377e-03 7.62644850e-05 1.34844426e-03 1.22517122e-05\n",
      " 5.48705691e-03 3.12632054e-01 1.48806194e-07 1.11693974e-10\n",
      " 4.33049572e-04 2.22195708e-03 1.71581105e-05 9.01114632e-08\n",
      " 1.77262881e-12 9.58044338e-11 4.36873233e-06 3.81094978e-09\n",
      " 3.16895978e-13 3.05260457e-08 1.22923637e-04 1.54280150e-03\n",
      " 6.74721360e-01 9.84901021e-07 1.27668795e-06 6.48200660e-11\n",
      " 2.38986002e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6098321e-05 3.3154732e-11 6.3658752e-11 1.6572301e-11 1.0940913e-03\n",
      " 7.6801123e-05 1.3519351e-03 1.2229828e-05 5.4958942e-03 3.1216103e-01\n",
      " 1.4990857e-07 1.1290237e-10 4.3067045e-04 2.2111426e-03 1.7199649e-05\n",
      " 9.0632746e-08 1.7901225e-12 9.6417756e-11 4.3749505e-06 3.8383328e-09\n",
      " 3.1935262e-13 3.0790336e-08 1.2294069e-04 1.5414617e-03 6.7519218e-01\n",
      " 9.9100203e-07 1.2815374e-06 6.5121783e-11 2.3936828e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.5948807e-05 3.2946472e-11 6.3269015e-11 1.6503229e-11 1.0917115e-03\n",
      " 7.6848715e-05 1.3508358e-03 1.2202806e-05 5.5016102e-03 3.1183079e-01\n",
      " 1.4973635e-07 1.1244661e-10 4.2983322e-04 2.2085696e-03 1.7217284e-05\n",
      " 9.0244683e-08 1.7732408e-12 9.5487729e-11 4.3524556e-06 3.8195367e-09\n",
      " 3.1681558e-13 3.0696008e-08 1.2326773e-04 1.5396663e-03 6.7552489e-01\n",
      " 9.8854946e-07 1.2772372e-06 6.4690996e-11 2.3962410e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.57501919e-05 3.27492963e-11 6.26263069e-11 1.62671491e-11\n",
      " 1.08918722e-03 7.62132840e-05 1.34763401e-03 1.22278370e-05\n",
      " 5.49537968e-03 3.12699974e-01 1.48778767e-07 1.11318135e-10\n",
      " 4.32167784e-04 2.21739686e-03 1.71048287e-05 8.98856243e-08\n",
      " 1.76017946e-12 9.53186627e-11 4.35985748e-06 3.80150356e-09\n",
      " 3.15818796e-13 3.04965333e-08 1.23131627e-04 1.53631286e-03\n",
      " 6.74661994e-01 9.80480195e-07 1.27192493e-06 6.43913534e-11\n",
      " 2.38706110e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Prediction vector: [4.6157009e-05 3.3158878e-11 6.3555584e-11 1.6559237e-11 1.0951746e-03\n",
      " 7.6878438e-05 1.3505184e-03 1.2218511e-05 5.5054580e-03 3.1162640e-01\n",
      " 1.4980314e-07 1.1292812e-10 4.3126379e-04 2.2109246e-03 1.7215552e-05\n",
      " 9.0376162e-08 1.7862430e-12 9.6114353e-11 4.3795303e-06 3.8500612e-09\n",
      " 3.1902053e-13 3.0786087e-08 1.2321009e-04 1.5428885e-03 6.7571598e-01\n",
      " 9.9002273e-07 1.2803965e-06 6.4960579e-11 2.3875959e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction vector: [4.6152163e-05 3.3194378e-11 6.3535815e-11 1.6490524e-11 1.0911931e-03\n",
      " 7.6553741e-05 1.3488102e-03 1.2240446e-05 5.4823542e-03 3.1221968e-01\n",
      " 1.4931290e-07 1.1276582e-10 4.3308441e-04 2.2168658e-03 1.7189466e-05\n",
      " 9.0687998e-08 1.7933811e-12 9.6416569e-11 4.3871510e-06 3.8525805e-09\n",
      " 3.1936145e-13 3.0696079e-08 1.2304191e-04 1.5367023e-03 6.7515033e-01\n",
      " 9.8703970e-07 1.2804734e-06 6.5314656e-11 2.3884141e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction vector: [4.59833609e-05 3.29290137e-11 6.31072902e-11 1.64561160e-11\n",
      " 1.09545211e-03 7.67050733e-05 1.34812377e-03 1.22200672e-05\n",
      " 5.50227845e-03 3.11406761e-01 1.48987979e-07 1.11908094e-10\n",
      " 4.30745102e-04 2.20896909e-03 1.71929551e-05 9.01176733e-08\n",
      " 1.77381970e-12 9.54728241e-11 4.36656728e-06 3.82173093e-09\n",
      " 3.15972590e-13 3.05845624e-08 1.22866113e-04 1.54109451e-03\n",
      " 6.75946474e-01 9.88248871e-07 1.27485350e-06 6.47149556e-11\n",
      " 2.38212160e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Prediction vector: [4.6032896e-05 3.2941264e-11 6.3117039e-11 1.6354017e-11 1.0954364e-03\n",
      " 7.6324752e-05 1.3466532e-03 1.2206602e-05 5.4939147e-03 3.1180111e-01\n",
      " 1.4886797e-07 1.1194012e-10 4.3294104e-04 2.2157459e-03 1.7145634e-05\n",
      " 8.9923823e-08 1.7729674e-12 9.5590529e-11 4.3737818e-06 3.8233638e-09\n",
      " 3.1760705e-13 3.0622857e-08 1.2290948e-04 1.5446421e-03 6.7554951e-01\n",
      " 9.8944372e-07 1.2793208e-06 6.4550261e-11 2.3842626e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6168825e-05 3.3278231e-11 6.3677126e-11 1.6540542e-11 1.0900152e-03\n",
      " 7.6408855e-05 1.3534509e-03 1.2328577e-05 5.5116517e-03 3.1336966e-01\n",
      " 1.5062217e-07 1.1325853e-10 4.3498186e-04 2.2269755e-03 1.7241207e-05\n",
      " 9.0836664e-08 1.8002518e-12 9.7222043e-11 4.3665996e-06 3.8392578e-09\n",
      " 3.2061371e-13 3.0824083e-08 1.2347056e-04 1.5408694e-03 6.7394966e-01\n",
      " 9.9064926e-07 1.2897393e-06 6.5490523e-11 2.4020686e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Prediction vector: [4.6279256e-05 3.3326123e-11 6.3915748e-11 1.6718224e-11 1.0935417e-03\n",
      " 7.7123012e-05 1.3554891e-03 1.2264664e-05 5.5066212e-03 3.1145763e-01\n",
      " 1.5126808e-07 1.1374649e-10 4.3193757e-04 2.2150683e-03 1.7309547e-05\n",
      " 9.0889870e-08 1.8038985e-12 9.6686499e-11 4.3636401e-06 3.8796042e-09\n",
      " 3.2123130e-13 3.0978622e-08 1.2401068e-04 1.5366019e-03 6.7587930e-01\n",
      " 9.9504450e-07 1.2857395e-06 6.5777071e-11 2.3985274e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6253826e-05 3.3393528e-11 6.3836353e-11 1.6746224e-11 1.0890953e-03\n",
      " 7.6902790e-05 1.3570850e-03 1.2349176e-05 5.5209007e-03 3.1228885e-01\n",
      " 1.5192281e-07 1.1383186e-10 4.3507654e-04 2.2212446e-03 1.7373924e-05\n",
      " 9.1251749e-08 1.8165366e-12 9.7476298e-11 4.3500227e-06 3.8718961e-09\n",
      " 3.2168707e-13 3.0947341e-08 1.2476523e-04 1.5281831e-03 6.7503458e-01\n",
      " 9.9388058e-07 1.2922802e-06 6.6396902e-11 2.4056442e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.63683391e-05 3.36595127e-11 6.42229395e-11 1.68095676e-11\n",
      " 1.08969153e-03 7.68945029e-05 1.36145216e-03 1.23721038e-05\n",
      " 5.52384695e-03 3.13074410e-01 1.52795621e-07 1.14712496e-10\n",
      " 4.36064700e-04 2.22561136e-03 1.73694007e-05 9.15457576e-08\n",
      " 1.82523831e-12 9.83569545e-11 4.36287246e-06 3.89427468e-09\n",
      " 3.24950190e-13 3.11333892e-08 1.24950602e-04 1.53049850e-03\n",
      " 6.74232244e-01 9.95554728e-07 1.29463990e-06 6.66635705e-11\n",
      " 2.41273883e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.61257405e-05 3.33899713e-11 6.37747910e-11 1.67062857e-11\n",
      " 1.09086104e-03 7.67328529e-05 1.35826226e-03 1.23418104e-05\n",
      " 5.51973330e-03 3.12516391e-01 1.51612397e-07 1.13555616e-10\n",
      " 4.34587768e-04 2.21983064e-03 1.73244916e-05 9.12242868e-08\n",
      " 1.80793032e-12 9.73871261e-11 4.35735637e-06 3.86127752e-09\n",
      " 3.21420381e-13 3.09492982e-08 1.24352708e-04 1.53033540e-03\n",
      " 6.74805641e-01 9.92734613e-07 1.28766237e-06 6.62503039e-11\n",
      " 2.40588342e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Prediction vector: [4.6196168e-05 3.3388944e-11 6.4012906e-11 1.6747503e-11 1.0872129e-03\n",
      " 7.6872006e-05 1.3588930e-03 1.2350863e-05 5.5290600e-03 3.1318629e-01\n",
      " 1.5236769e-07 1.1414755e-10 4.3460174e-04 2.2202758e-03 1.7359882e-05\n",
      " 9.1371760e-08 1.8169769e-12 9.7499370e-11 4.3409350e-06 3.8607024e-09\n",
      " 3.2093330e-13 3.0943802e-08 1.2461800e-04 1.5294539e-03 6.7412883e-01\n",
      " 9.9356214e-07 1.2936985e-06 6.6324002e-11 2.4107694e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.62210155e-05 3.34923304e-11 6.42282616e-11 1.67511734e-11\n",
      " 1.08437333e-03 7.68966274e-05 1.35872560e-03 1.23614891e-05\n",
      " 5.51896589e-03 3.13867241e-01 1.52422459e-07 1.14654425e-10\n",
      " 4.35674825e-04 2.21928908e-03 1.73294757e-05 9.17179932e-08\n",
      " 1.82677593e-12 9.80792253e-11 4.36736855e-06 3.88082722e-09\n",
      " 3.22741671e-13 3.10221004e-08 1.24666840e-04 1.52591988e-03\n",
      " 6.73464298e-01 9.91267825e-07 1.29348473e-06 6.65932309e-11\n",
      " 2.41057700e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6282756e-05 3.3362320e-11 6.4196405e-11 1.6817533e-11 1.0934639e-03\n",
      " 7.7386270e-05 1.3568451e-03 1.2319789e-05 5.5328817e-03 3.1195655e-01\n",
      " 1.5172526e-07 1.1423005e-10 4.3339300e-04 2.2150078e-03 1.7372129e-05\n",
      " 9.1515446e-08 1.8140882e-12 9.7020156e-11 4.3665718e-06 3.8768015e-09\n",
      " 3.1959049e-13 3.0946445e-08 1.2440077e-04 1.5319786e-03 6.7535502e-01\n",
      " 9.9514352e-07 1.2880668e-06 6.6120234e-11 2.4025228e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction vector: [4.6473659e-05 3.3513803e-11 6.4554584e-11 1.6939290e-11 1.0920134e-03\n",
      " 7.7642508e-05 1.3617305e-03 1.2360051e-05 5.5294787e-03 3.1307754e-01\n",
      " 1.5214289e-07 1.1465507e-10 4.3232765e-04 2.2117079e-03 1.7397333e-05\n",
      " 9.2064496e-08 1.8267725e-12 9.7474799e-11 4.3664354e-06 3.8797690e-09\n",
      " 3.2014699e-13 3.0937070e-08 1.2424157e-04 1.5239551e-03 6.7424572e-01\n",
      " 9.9341992e-07 1.2897412e-06 6.6380054e-11 2.4045131e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6461089e-05 3.3474268e-11 6.4545869e-11 1.6959307e-11 1.0904954e-03\n",
      " 7.7653647e-05 1.3599278e-03 1.2297270e-05 5.5228719e-03 3.1270048e-01\n",
      " 1.5241014e-07 1.1513351e-10 4.3192101e-04 2.2062422e-03 1.7386326e-05\n",
      " 9.1801681e-08 1.8254738e-12 9.7382477e-11 4.3584200e-06 3.8885122e-09\n",
      " 3.2086784e-13 3.0992300e-08 1.2422599e-04 1.5254773e-03 6.7463702e-01\n",
      " 9.9517263e-07 1.2903913e-06 6.6074389e-11 2.4057066e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Prediction vector: [4.62961689e-05 3.34143789e-11 6.40111020e-11 1.68118384e-11\n",
      " 1.09381939e-03 7.72350468e-05 1.35838694e-03 1.23312366e-05\n",
      " 5.54254651e-03 3.12492937e-01 1.52479387e-07 1.14232984e-10\n",
      " 4.34629299e-04 2.21807370e-03 1.73541612e-05 9.11888236e-08\n",
      " 1.80876895e-12 9.72180739e-11 4.34993353e-06 3.86749965e-09\n",
      " 3.20440452e-13 3.09785975e-08 1.24836821e-04 1.53221749e-03\n",
      " 6.74801946e-01 9.94026095e-07 1.28948511e-06 6.60464322e-11\n",
      " 2.40413850e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction vector: [4.6254921e-05 3.3398843e-11 6.3686091e-11 1.6702249e-11 1.0949762e-03\n",
      " 7.6932498e-05 1.3562297e-03 1.2333428e-05 5.5457866e-03 3.1262344e-01\n",
      " 1.5201742e-07 1.1380438e-10 4.3626939e-04 2.2217368e-03 1.7345001e-05\n",
      " 9.0924679e-08 1.8051060e-12 9.7156005e-11 4.3596406e-06 3.8632391e-09\n",
      " 3.2083621e-13 3.0869078e-08 1.2483328e-04 1.5350765e-03 6.7466187e-01\n",
      " 9.9226190e-07 1.2866319e-06 6.5947893e-11 2.3998696e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6149074e-05 3.3233142e-11 6.3697797e-11 1.6716411e-11 1.0902099e-03\n",
      " 7.6956763e-05 1.3561252e-03 1.2327168e-05 5.5318926e-03 3.1246793e-01\n",
      " 1.5167360e-07 1.1363550e-10 4.3401920e-04 2.2134080e-03 1.7327107e-05\n",
      " 9.1147868e-08 1.8060199e-12 9.7046982e-11 4.3486025e-06 3.8543067e-09\n",
      " 3.1920609e-13 3.0852735e-08 1.2443862e-04 1.5305752e-03 6.7485154e-01\n",
      " 9.9177726e-07 1.2863482e-06 6.6071197e-11 2.4021701e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6203786e-05 3.3278411e-11 6.3955237e-11 1.6778180e-11 1.0930811e-03\n",
      " 7.7232944e-05 1.3559446e-03 1.2346599e-05 5.5433051e-03 3.1233397e-01\n",
      " 1.5203643e-07 1.1401971e-10 4.3430549e-04 2.2188926e-03 1.7380373e-05\n",
      " 9.1141480e-08 1.8080592e-12 9.6960349e-11 4.3456816e-06 3.8563490e-09\n",
      " 3.1886088e-13 3.0915160e-08 1.2458426e-04 1.5336405e-03 6.7496186e-01\n",
      " 9.9592614e-07 1.2907690e-06 6.5849111e-11 2.4036560e-04]\n",
      "Predicted vector size: (1, 29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction vector: [4.6142730e-05 3.3039391e-11 6.3730902e-11 1.6714607e-11 1.0897949e-03\n",
      " 7.7418670e-05 1.3528033e-03 1.2300029e-05 5.5231284e-03 3.1185597e-01\n",
      " 1.5067161e-07 1.1319408e-10 4.3152343e-04 2.2040808e-03 1.7311942e-05\n",
      " 9.1148820e-08 1.7988534e-12 9.6103042e-11 4.3502773e-06 3.8423749e-09\n",
      " 3.1504912e-13 3.0736761e-08 1.2410014e-04 1.5258363e-03 6.7549342e-01\n",
      " 9.8947203e-07 1.2829360e-06 6.5604487e-11 2.3929085e-04]\n",
      "Predicted vector size: (1, 29)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('asl_cnn_model.keras')\n",
    "labels = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "img_size = 64\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"📷 Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get bounding box of hand\n",
    "            h, w, _ = frame.shape\n",
    "            x_coords = [lm.x for lm in hand_landmarks.landmark]\n",
    "            y_coords = [lm.y for lm in hand_landmarks.landmark]\n",
    "            padding = 70\n",
    "            x_min = max(int(min(x_coords) * w) - padding, 0)\n",
    "            x_max = min(int(max(x_coords) * w) + padding, w)\n",
    "            y_min = max(int(min(y_coords) * h) - padding, 0)\n",
    "            y_max = min(int(max(y_coords) * h) + padding, h)\n",
    "\n",
    "            # Clamp values\n",
    "            x_min = max(x_min, 0)\n",
    "            y_min = max(y_min, 0)\n",
    "            x_max = min(x_max, w)\n",
    "            y_max = min(y_max, h)\n",
    "\n",
    "            # Extract hand ROI\n",
    "            hand_img = frame[y_min:y_max, x_min:x_max]\n",
    "            if hand_img.size == 0:\n",
    "                continue  # skip if invalid crop\n",
    "\n",
    "            # Preprocess for model\n",
    "            hand_resized = cv2.resize(hand_img, (img_size, img_size))\n",
    "            hand_input = hand_resized.astype(\"float32\") / 255.0\n",
    "            hand_input = np.expand_dims(hand_input, axis=0)\n",
    "\n",
    "            cv2.imshow(\"Hand Input\", hand_resized)\n",
    "\n",
    "\n",
    "            # Predict\n",
    "            prediction = model.predict(hand_input)\n",
    "            pred_idx = np.argmax(prediction[0])\n",
    "            pred_label = labels[pred_idx]\n",
    "            confidence = prediction[0][pred_idx]\n",
    "\n",
    "            print(\"Prediction vector:\", prediction[0])\n",
    "            print(\"Predicted vector size:\", prediction.shape)\n",
    "\n",
    "\n",
    "            # Draw landmarks & label\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            cv2.putText(frame, f'{pred_label} ({confidence:.3f})', (x_min, y_min - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"ASL Recognizer\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl-recognizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
